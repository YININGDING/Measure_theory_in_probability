\newpage
\section{Discrete time martingales}
\subsection*{Discrete time stochastic process}

$\{X_n, n\geq 0\}$ discrete time stochastic process
\begin{example}
Consider coin tossing on infinite time horizon: Let $\Omega = \{0,1\}^\N, N = \{1,2,3,...\}, \omega\in\Omega, \omega = (\omega_1, \omega_2, ...)$ with $\omega_n = 0/1$
Fix $n\geq 1,i_1,i_2, ... = 0/1$ and $p \in (0,1)$ \\
Consider cylinders (up to time n) $C(i_1, ..., i_n) = \{\omega\in\Omega, \omega_k = i_k, k\leq n\}$ \\
Then everything is finite and nice:
$\F_n = \sigma(C(i_1, ..., i_n)), \prob_n$ defined on $\F_n$ as:
\begin{equation*}
    \prob_n(C(i_1, ..., i_n)) = p^{\bigs{k}i_k}\cdot (1-p)^{n-\bigs{k}i_k}
\end{equation*}which is well-defined probability
\end{example}

\begin{rem}
$\Omega = \{0,1\}^\N$ is uncountable, same cardinality as $[0,1]\in\R$ hence $\prob(\{\omega\}) = 0$ (This also makes sense as p <1 and infinite sequence)
\begin{enumerate}
    \item $F_n \subset \F_{n+1}$ and $\prob_{n+1}(A)= \prob_n(A), A\in \F_n$
    \item $A\in\bigu{n}F_n$ be algebra but not $\sigma$-algebra
    \item Define $\F := \sigma(\bigu{n}F_n)$ and extend probability uniquely to this sigma algebra as $\prob(A) := \prob_n(A), A\in\F_n$
\end{enumerate}
\end{rem}
\vspace{2cm}
\begin{dfn}[Filtration] Let $(\Omega, \F)$ be mesurable space, A family of $\sigma$-algebra $\F_n, n\geq 0$ is a filtration if:
\begin{enumerate}
    \item $\F_n\subset\F_, n\geq 0$
    \item $\F_n \subset \F_{n+1}, n\geq 0$
\end{enumerate}
\end{dfn}
\textbf{Notice: This is known as information available at time n}
\begin{example}
Let $(\Omega, \F)$ be mesurable space define $X_n, n\geq 0$ r.v on measurable set, $\F_n := \sigma(X_1, ..., X_n)$ is a natural filtration.
\end{example}

\newpage
\subsection*{Stopping times}
\begin{dfn}[Stopping times]
Let $(\Omega, \F)$ be mesurable space and $(\F_n)$ be filtration. An random variable $\tau: \Omega \mapsto \{0,1,2, ..., \infty\}$ is a stopping time if:
\begin{equation*}
    \forall n\geq 0 \qquad \{\tau \leq n  \}\in\F_n
\end{equation*}
\end{dfn}

\begin{rem}
The above definition is equivalent to 
\begin{equation*}
    \forall n\geq 0 \qquad \{\tau = n  \}\in\F_n
\end{equation*}
\pf:
\vspace{4cm}
\end{rem}
\begin{lem}
Let $(\Omega, \F, (\F_n))$ be given $\tau_1, \tau_2$ be stopping times defined above. Then:
\begin{enumerate}
    \item $\tau_1\wedge \tau_2$ and $\tau_1\vee \tau_2$ are stopping times
    \item $\forall n_0 \geq 1, \tau_0 := n_0$ being constant. $\tau_0$ is a stopping time
\end{enumerate}
\end{lem}
\pf 
\vspace{8cm}
\begin{dfn}[Adapted process] $(X_n)$ is an adapted sequence/process if $\forall n, X_n \in \F_n$ that is $\F_n$ measurable. Denote the pair: $(X_n, \F_n)$

\end{dfn}
\newpage
\begin{dfn}[First hitting time]
Let $B\in \B(\R)$ be Borel set, and let $(X_n, \F_n)$ be given, Define first hitting time: 
\begin{equation*}
    \tau_B := \inf \{n\geq 0, X_n\in B\}
\end{equation*}
\end{dfn}
\textbf{Claim:} First hitting time is a stopping time \\
\pf \vspace{4cm}

Then we consider $\F_\tau$.
\begin{dfn}
$A\in \F_\tau$ if $A\in \F$ being measurable and 
\begin{align*}
    \forall n\quad A\cap \{\tau \leq n\} \in \F_n \\
    \intertext{or}
    \forall n \quad A\cap \{\tau = n\} \in \F_n
\end{align*}
\end{dfn}
\begin{thm}
Consider $\F_\tau$
\begin{enumerate}
    \item $\F_\tau$ is a $\sigma$-algebra
    \item $A\in \F_\tau$ iff $A\cap \{\tau = n\}\in \F_n, \forall n$
    \item $\tau_1 \leq \tau_2$ both being stopping time, then $\F_{\tau_1}\subset \F_{\tau_2}$
\end{enumerate}
\end{thm}
\pf

\vfill
Let $(X_n, \F_n)$ be given, $\tau$-stopping time Then $X_\tau\I_{\{\tau < \infty\}}$ is an random variable \\
\pf 
\begin{equation*}
    X_\tau\I_{\{\tau < \infty\}} = \bigs{n=0}^\infty X_n \I_{\{\tau =n\}}
\end{equation*}Since $X_n$ is adapted, $X_n\in \F_n$, $\{\tau = n\} \in \F_n \implies \I_{\{\tau =n\}} \in \F_n$ Hence it is $\F$-measurable. \\
$\tau$ is $\F_\tau$ measurable, this is trivial by definition.

\newpage 
\subsection{Martingales}
\begin{dfn}[Martingale] $(\Omega, \F, (\F_n), \prob)$ stochastic basis given, A stochastic process $\{X_n, n\geq 0\}$ is a martingale if 
\begin{enumerate}
    \item $(X_n)$ is $(F_n)$ adapted, that is $X_n\in\F_n$
    \item $\E|X_n| < \infty, \forall n$
    \item $\forall n\geq m\geq 0$
    \begin{equation*}
        X_m = \E(X_n| \F_m)
    \end{equation*}
    \begin{enumerate}
        \item (Supermartingale) $\forall n\geq m\geq 0$
        \begin{equation*}
        X_m \geq \E(X_n| \F_m)
    \end{equation*}
    \item (Submartingale) $\forall n\geq m\geq 0$
        \begin{equation*}
        X_m \leq \E(X_n| \F_m)
    \end{equation*}
    \end{enumerate}
\end{enumerate}
\end{dfn}
\begin{lem}
$(\Omega, \F, (\F_n), \prob)$ stochastic basis given, A stochastic process $\{X_n, n\geq 0\}$ is a martingale iff $1, 2$ above holds plus: 
\begin{equation*}
    \E(X_{n+1}|\F_n) = \E(X_n) \qquad \forall n
\end{equation*}
\end{lem}
\pf By induction

\newpage
\begin{example}
$\xi_k, k\geq 1$ be independent and $\E|\xi_k|<\infty, \E(\xi_k) = 0$ Define initial value $X_0 = x \in \R, X_n := x + \bigs{i=1}^n \xi_i$, $\F_0 = \{\emptyset,\Omega\}, \F_n = \sigma(\xi_1, ..., \xi_n), n\geq 1$
\end{example}
Claim: This $X_n$ is martingale
\begin{enumerate}
    \item $\xi_k \in \F_k, \forall k\leq n, \F_k \subset \F_n\implies x + \bigs{i=1}^n \xi_i \in \F_n $, Adapted
    \item $\E|X_n| \leq |x| + \bigs{i=1}^n \E|\xi_i| < \infty,\forall n$
    \item Martingale property:
    \begin{equation*}
        \E(X_{n+1}|\F_n) = \E(X_{n} +\xi_{n+1}|\F_n) = \E(X_{n}|\F_n) +\E(\xi_{n+1}|\F_n) = X_{n} + \E(\xi_{n+1}) = X_{n}
    \end{equation*}
\end{enumerate}
\vspace{2cm}
\begin{example}[Levy martingale]
Let $X$ be R.V with $\E|X|<\infty, (\F_n)$ filtration Define \begin{equation*}
    M_n := \E(X | \F_n)
\end{equation*}
Claim: This $M_n$ is martingale
\begin{enumerate}
    \item By definition of conditional distribution.
    \item $\E|M_n| =\E|\E(X | \F_n)| \leq \E(\E(|X| | \F_n)) = \E|X| < \infty$
    \item Martingale property:
    \begin{equation*}
        \E(M_{n+1}|\F_n) = \E(\E(X |\F_{n+1})|\F_n) = \E(X|\F_n) = X_{n}
    \end{equation*}
\end{enumerate}
\end{example}
\vspace{2cm}
\begin{prop}
Let $(X_n, \F_n)$ be a martingale, $p \geq 1, \E|X_n|^p < \infty, \forall n$ Then the pair $(|X_n|^p, \F_n)$ is a submartingale.
\end{prop}
\pf
\newpage
$(X_n, \F_n)$ be submartingale $\tau$ stopping time then stopped process:
\begin{equation*}
    Y_n = X_{\tau \wedge n}
\end{equation*}and $(Y_n, \F_n)$ is a submartingale
\pf\vspace{10cm}

\begin{thm}[Doob/ Optional Stopping Theorem]
\label{Doob} Let $(X_n, \F_n)$ be a martingale, $\tau_i, i=1,2$ be stopping times Assume
\begin{enumerate}
    \item $\prob(\tau_1 \leq \tau_2 < \infty) = 1$
    \item $\E|X_{\tau_i}| < \infty$
    \item $\linf{n\rightarrow \infty} \E[|X_n|\I_{\tau_i > n}] = 0, i=1,2$
\end{enumerate}Then 
\begin{equation*}
    \E(X_{\tau_2}|\F_{\tau_1}) = X_{\tau_1}
\end{equation*}
\end{thm}
\pf
\newpage
Consider conditions in Doob Theorem \ref{Doob} $\linf{n\rightarrow \infty} \E[|X_n|\I_{\tau_i > n}] = 0, i=1,2$ and $\E|X_{\tau_i}| < \infty$ We provide few sufficient conditions for (2) and (3) here:
\begin{enumerate}
    \item If $\exists K>0$ s.t.\begin{equation*}
        \prob(\tau_1 \leq K) = \prob(\tau_2 \leq K) = 1
    \end{equation*}
    \pf \vspace{4cm}
    \item If $\exists c >0 $ s.t. $\forall n, \prob(|X_n| \leq c) = 1$ \\
    \pf
    \begin{equation*}
    \E|X_{\tau_i}| < c < \infty, \E[|X_n|\I_{\tau_i > n}] \leq c\prob(\tau_i > n) \xrightarrow{n\rightarrow \infty} 0
    \end{equation*}
    \item If $\exists c >0 $ s.t. 
    \begin{enumerate}
        \item $\E(\abs{X_{n+1} - X_n} \big|\F_n) \leq c$ a.s.
        \item $\E[\tau_i] < \infty$
    \end{enumerate} 
\end{enumerate}

\begin{rem}[Tail probability] Let $X \geq 0$
\begin{enumerate}
    \item $\E(X) = \int_0^\infty \prob(X > t) \diff t$
    \item If $X$ takes value $0,1,...$ then $\E(X) = \bigs{n=0}^\infty \prob(X > n)$
\end{enumerate}

\end{rem}
\pf
\newpage
\begin{example}
$S_0 = x, S_n = x + \xi_1 +... +\xi_n$ with $\prob(\xi_k = \pm 1) = \frac{1}{2}$ being independent random variables also $\E(\xi_k) = 0$. $\F_n = \sigma(\xi_1, ..., \xi_n)$, then $(S_n, \F_n)$ is martingale. \\
Assume $0 < x<a$ and define stopping time $\tau_a = \inf \{n\geq 0, S_n = a \text{ or } S_n = 0\}, \tau_0 = 0$ as constant \\[0.5cm]
\textbf{Check:} $\E(|S_{n+1}-S_n|\big| \F_n) = 1$ given by the jump size. $\E(\tau_a) < \infty$ is shown below. By previous theorem, we have $\E(X_{\tau_a}) = x$ Since  $\E(\tau_a) < \infty$, this game will end eventually then we have following:
\begin{align*}
    \E(S_{\tau_a}) =0 \cdot \prob(S_{\tau_a} = 0) + a\prob(S_{\tau_a} = a) = x \\
    \prob(S_{\tau_a} = a) = \frac{x}{a}, \prob(S_{\tau_a} = 0) = \frac{a-x}{a}
\end{align*}
\end{example}

\textbf{Claim: $\E(\tau_a) < \infty$} \\
Fix $m\geq 1$ Define $A_m := \{\xi_{m+1} = 1, ..., \xi_{m+a} = 1\}$ Then by $\prob(A_m) = (\frac{1}{2})^a$ by independency.
\begin{align*}
    \{\tau > ma\} &\subset \bigi{k=0}^{m-1} A_K^c \\
    \prob(\tau > ma) &\leq \prob(\bigi{k=0}^{m-1} A_K^c) \\
    &= \bigp{k=0}^{m-1} \prob(A_K^c) = (1-(\frac{1}{2})^a)^m 
    \intertext{Denote $q := 1-(\frac{1}{2})^a$, $q \in (0,1)$}
    \prob(\tau > ma) &\leq q^m \\
    \E(\tau) &= \bigs{j=1}^\infty \prob(\tau > j) = \bigs{m}\bigs{i=1}^{a-1}\prob(\tau > ma+i) \\
    &\leq \bigs{m} a\prob(\tau > ma) \leq a \bigs{m} q^m < \infty
\end{align*}

\begin{rem}Also note the following:
\begin{enumerate}
    \item We could show stronger version: $\forall N\geq 1, \E(\tau^N)< \infty$ 
    \begin{align*}
        \E(\tau^N) &= N\int_0^\infty t^{N-1} \prob(X > t) \diff t \\
        &\leq N \bigs{n}\int_n^{n+1} (n+1)^N \prob(X > t) \diff t \\
        &\leq N\bigs{n} (n+1)^N \prob(X > t) \int_n^{n+1} \diff t \\
        &\leq N\bigs{n} (n+1)^N q^n <\infty
    \end{align*}
    \item This example makes sense, as the winning rate is $\frac{x}{a}$ which is the relative distance between upper bound and starting value.
\end{enumerate}
\end{rem}
\newpage
Now we know $\E(\tau_a) < \infty$ but what is exactly the value is? What is the mean time to end the game? i.e. $\E(\tau_a) =?$ \\
Construction: $M_n = S_n^2 - n$, claim: This is a martingale.
\begin{enumerate}
    \item $\F_n$ adapted, obvious.
    \item $\E\abs{M_n} \leq \E(S_n^2) + n < \infty$
    \item $M_{n+1} = (S_n + \xi_{n+1})^2 -n -1 = M_n + 2\xi_{n+1}S_n + \xi_{n+1}^2 -1$ 
    \begin{equation*}
        \E(M_{n+1} |\F_n) = \E(M_n + 2\xi_{n+1}S_n + \xi_{n+1}^2 -1|\F_n) = M_n + 1 -1 = M_n
    \end{equation*}
\end{enumerate}
Next, we use Doob's theorem \ref{Doob} 
\begin{enumerate}
    \item $\E\abs{M_{\tau_a}} \leq \E(S_{\tau_a}^2) + \E(\tau) <\infty$
    \item WTS: $\linf{n\rightarrow \infty} \E[|M_n|\I_{\tau_a > n}] = 0$
    \begin{align*}
        \E(\abs{M_n}\I_{\tau_a > n}) &\leq \E(S_n^2\I_{\tau_a > n}) + \E(n\I_{\tau_a > n}) \leq \E(S_n^2\I_{\tau_a > n}) + \E(\tau_a\I_{\tau_a > n}) \\
        \intertext{($S_n \leq a\implies S_n^2 \leq a^2$)}
        &\leq a^2 \prob(\tau_a > n) + \E(\tau_a\I_{\tau_a > n})
        \intertext{Passing limit and consider first half:}
        & \linf{n\rightarrow \infty} a^2 \prob(\tau_a > n) \xrightarrow{n\rightarrow \infty} 0
        \intertext{Second half:}
        0 \leq \tau_a\I_{\tau_a > n} \leq \tau, \E(\tau) <\infty \\
       \linf{n\rightarrow \infty}\E(\tau_a\I_{\tau_a > n}) = \biglim{n}\E(\tau_a\I_{\tau_a > n}) &\stackrel{DCT }{=}  \E(\tau_a\biglim{n} \I_{\tau_a > n})\xrightarrow{n\rightarrow \infty} 0
    \end{align*}Then we have desired result.
    \item $\E\abs{M_{0}} \leq x^2 <\infty$
    \item $\linf{n\rightarrow \infty} \E[|M_n|\I_{\tau > n}] = 0$ = $\linf{n\rightarrow \infty} \E[|M_n|\I_{0 > n}] = 0$
\end{enumerate}
By Doob's theorem $(\tau_1 = 0, \tau_a)$
\begin{align*}
    \E(M_{\tau_a}) = \E(M_0) = x^2 \implies &\E(S_{\tau_a}^2 ) -\E(\tau) = x^2 \implies a^2 \prob(S_{\tau_a} =a) -\E(\tau) = x^2 \\
    &\implies \E(\tau) = x(a-x)
\end{align*}

\begin{rem}
Still coin-tossing, but we remove lower bound of stopping time: now $\tau := \inf\{n\geq 1, S_n = x+1\}$ the rest settings stay the same.$\prob(\tau < \infty)=1$, $\E[\abs{S_{n+1}-S_n}\big| \F_n] = 1$. Assume $\E(\tau) <\infty$ Then by Doob's theorem \ref{Doob}
\begin{equation*}
    \E(S_\tau) = \E(S_0) = x \implies x+1 = x
\end{equation*}Contraction, hence the assumption is not true, that is: $\E(\tau) =\infty$
\end{rem}
\newpage

\begin{thm}[Maximal inequality]
\label{Maxinequal}
Let $(X_n, \F_n)$ be a submartingale, Then
\begin{equation*}
    \prob(\max\limits_{k\leq n} X_k > r) \leq \frac{1}{r} \E\abs{X_n} \qquad \forall r>0
\end{equation*}
\end{thm}
\pf \vspace{10cm}
\begin{example}
$X_n := \bigs{k=1}^m \xi_k, \E(\xi_k) = 0, \xi_k$ be independent. Then $(X_n, \F_n)$ is a martingale with $\F_n = \sigma(\xi_1, ..., \xi_n)$ \\
\textbf{Note: } If $\R \mapsto \R$ is convex and $\E\abs{f(X_n)} < \infty$ then $(f(X_n), \F_n)$ is a submartingale. \\
Let $f(t) = t^2, \E(\xi_k^2)<\infty$ Then apply previous theorem \ref{Maxinequal} we have 
\begin{align*}
    \prob(\max\limits_{k\leq n} \abs{\xi_1 + ,,, + \xi_k} > r) = \prob(\max\limits_{k\leq n} |X_k| > r) = \prob(\max\limits_{k\leq n} X_k^2 > r^2) &\leq \frac{1}{r^2}\E(X_n^2) = \frac{1}{r^2}\bigs{k=1}^n \E(\xi_k^2) \\
    \implies \prob(\max\limits_{k\leq n} \abs{\xi_1 + ,,, + \xi_k} > r) &\leq \frac{1}{r^2}\bigs{k=1}^n \E(\xi_k^2)
\end{align*}
\end{example}

\newpage
\begin{dfn}[Predictable] Let $\F_n$ be filtration, sequence of random variables $(\alpha_n)$ is called predictable if  $\F_{n-1}$-measurable. i.e.
\begin{equation*}
    \alpha_n \in \F_{n-1}
\end{equation*}
\end{dfn}
\begin{example}
Let $(M_n, \F_n)$ be a martingale, let $(\alpha_n, \F_n)$ be predictable. Define \begin{equation*}
    X_n = \bigs{k=1}^n \alpha_n (M_k - M_{k-1})
\end{equation*}Assume $\exists c >0, \prob(|\alpha_k| \leq c) = 1, \forall k$ Then: $M_n$ is martingale $\implies X_n$ martingale under $\F_n$
\begin{enumerate}
    \item $\E\abs{X_n} \leq c\bigs{k=1}^n \abs{M_k - M_{k-1}} \leq c\bigs{k=1}^n \abs{M_k}+ \abs{M_{k-1}} \leq \infty$
    \item $X_n\in\F_n$
    \item $X_{n+1}-X_n = \alpha_{n+1}(M_{n+1}-M_n), \alpha_{n+1}\in\F_n$
    \begin{equation*}
        \E(X_{n+1}-X_n|\F_n) = \alpha_{n+1}\E((M_{n+1}-M_n) |\F_n) = 0
    \end{equation*}
\end{enumerate}

\end{example}
\newpage
\subsection{Convergence with stopping time}

Consider $x_0 = 0$ Fix $a,b\in\R, a<b$ and Define:
\begin{align*}
    \tau_0 &= \inf\{n\geq 0, x_n < a\} \\
    \tau_1 &= \inf\{n > \tau_0, x_n > b\} \\
    \tau_2 &= \inf\{n > \tau_1, x_n < a\} \\
    ...\\
    \tau_{2k} &= \inf\{n > \tau_{2k-1}, x_n < a\} \\
    \tau_{2k+1} &= \inf\{n > \tau_{2k}, x_n > b\}
    \intertext{Define number of upcrossing of $(a,b)$ }
    u_a^b &= \begin{cases}
    \sup\{k\geq 1, \tau_{2k-1} <\infty\} & \tau_1 < \infty \\
    0 &\tau_1 = \infty
    \end{cases}
\end{align*}
\begin{lem}
Let $(x_n)$ converges (perhaps $\infty$) iff $\uab <\infty$ for every pair of rationals $a<b$
\end{lem}
\pf \begin{enumerate}
    \item $\implies$ Proof by contradiction \\
    Assume $\exists a,b\in \Q$ s.t. $\uab = \infty$ then we define two subsequences $\{x_{\tau_{2k}}, k\geq 1\},\{x_{\tau_{2k+1}}, k\geq 1\}$, the distance between two subsequences are always larger than $b-a$ then limit does not exists
    \item $\impliedby$ Proof by contrapositive statement. \\
    If $x_n$ is not convergent then $\exists a,b\in \Q, a<b$ s.t. 
    \begin{equation*}
        \linf{n} x_n < a<b<\lsup{n} x_n
    \end{equation*}Then exists subsequences $(k_n, l_n)$ s.t. $x_{k_n} < a, x_{l_n} > b$ define:
    \begin{align*}
    \tau_0 &= \inf\{k_n, x_{k_n} < a\} \\
    \tau_1 &= \inf\{l_n > \tau_0, x_{l_n} > b\} \\
    ...\\
    \uab &= \infty
\end{align*}
\end{enumerate}
\qed
\begin{lem}[Upcrossing lemma] Let $(X_n, \F_n)$ be a supermartingale and define \begin{equation*}
    \uab(m) :=\text{ number of upcrossing before time }m
\end{equation*}Then $\forall a<b$
\begin{equation*}
    \E(\uab(m)) \leq \frac{1}{b-a} \E(X_m -a)^-
\end{equation*}

\end{lem}
\pf 

\newpage
\begin{thm}[(Super) Martingale Convergence theorem]
\label{SMCT}
Let $(X_n, \F_n)$ be a supermartingale assume
\begin{equation*}
    \sup\limits_n \E[X_n^-] < \infty
\end{equation*}Then there exists a r.v. $X_\infty$ s.t.
\begin{enumerate}
    \item $\E\abs{X_\infty} <\infty$
    \item $\biglim{n} X_n = X_\infty$ a.s.
\end{enumerate}
\end{thm}
\pf \vfill
\begin{cor} Every non-negative supermartingale converges
\begin{equation*}
    \sup\limits_n \E[X_n^-] = 0 < \infty
\end{equation*}
\end{cor}
\begin{cor}If $(X_n, \F_n)$ is a submartingale and \begin{equation*}
    \sup\limits_n \E[X_n^+] < \infty
\end{equation*} Then $\E\abs{X_\infty} <\infty$ and $\biglim{n} X_n = X_\infty$ a.s.
\end{cor}
\pf Consider $(-X_n, \F_n)$ be supermartingale. $\sup\limits_n \E[(-X_n)^-] =\sup\limits_n \E[(X_n)^+]  < \infty$
    
Then every thing follows
\begin{example}
Given $X\in \ls{1}$ be r.v. Consider Levy martingale $M_n = \E(X|\F_n)$
\begin{equation*}
    \sup\limits_n \E[M_n^-] = \sup\limits_n \E[\E(X|\F_n)^-] \stackrel{\text{Jensen}}{\leq} \sup\limits_n \E[\E(X^-|\F_n)] = \E[X^-] \leq\E\abs{X} <\infty
\end{equation*}Then $M_n \rightarrow M_\infty $ a.s. and $\E(M_\infty)<\infty$
\end{example}
\newpage \textbf{Question: When does the expectation also converge? i.e.}  \begin{equation*}
    \biglim{n}\E(X_n) =  \E(X_\infty)
\end{equation*}
\textbf{Answer: we need uniform integrability}

\subsection{Uniform integrability}
\begin{dfn}[Uniform integrability]
A family of r.vs $\{X_\alpha; \alpha\in A\}$ is uniform integrability if 
\begin{equation*}
    \adjustlimits\lim_{c\rightarrow \infty} \sup_{\alpha\in A}\E[\abs{X_\alpha} \I_{(\abs{X_\alpha > c})}] =0
\end{equation*}
\end{dfn}

\begin{example}
If $\abs{X_n} \leq Y, \E[Y] < \infty$ Then
\begin{equation*}
    \sup\limits_{\alpha\in A}\E[\abs{X_\alpha} \I_{(\abs{X_\alpha > c})}] \leq  \E[Y \I_{(Y > c)}] \xrightarrow{c\rightarrow \infty} 0
\end{equation*}
\textbf{Special case:} $\E\abs{X_k} < \infty, k = 1,...,n$ Then the family $\{X_k; k\leq n\}$ is uniform integrability \\
\pf Define $Y:= \bigs{k=1}^n \abs{X_k}$
\end{example}
\vspace{1cm}
\begin{prop} $\{X_\alpha; \alpha\in A\}$ is uniform integrable iff
\begin{enumerate}
    \item $\supunder{\alpha} \E\abs{X_\alpha} < \infty$
    \item $\forall \epsilon >0,\exists \delta>0 $ s.t. if $\prob(A)<\delta $ then \begin{equation*}
        \supunder{\alpha} \E[\abs{X_\alpha}\I_A] < \epsilon
    \end{equation*}
\end{enumerate}
\end{prop}
\begin{cor}
    $\{X_n; n\geq1 \}$ r.vs assume that for a certain $p >1$\begin{equation*}
        M = \supunder{n} \E\abs{X_\alpha}^p < \infty
    \end{equation*} then $\{X_n; n\geq1 \}$ is uniform integrable
\end{cor}

\newpage
\pf
\newpage
\begin{thm}
If $X_n \xrightarrow{\ls{1}} X$ then $\{X_n, n\in \N \}$ is uniform integrable.
\end{thm}
\vspace{12cm}
\begin{thm}
If $\{X_n, n\in \N \}$ is uniform integrable and $X_n \xrightarrow{\prob} X$ then $X_n \xrightarrow{\ls{1}} X$
\end{thm}\pf

\newpage
\begin{lem}
    Let $\E\abs{X} < \infty, \{\F_\alpha, \alpha\in A\}$ be family of $\sigma$-algebra then \begin{equation*}
        \{\E(X|\F_\alpha); \alpha\in A\}
    \end{equation*} is uniform integrable
\end{lem}

\newpage
\begin{thm}
Let $(X_n, \F_n)$ be uniform integrable submartingale, then there exists a r.v. $X$ s.t.\begin{enumerate}
    \item $X_n \xrightarrow{a.s.} X$
    \item $X_n \xrightarrow{\ls{1}} X$
    \item If $(X_n, \F_n)$ is martingale then we may extend the definition of martingale to infinity: \begin{equation*}
        X_n = \E(X|\F_n); \quad X = X_\infty
    \end{equation*}
\end{enumerate}
\end{thm}
\pf
\newpage
\subsection{Backward martingale}
Let $\{\F_{-n}; n\geq 0\}$ be filtration s.t. \begin{equation*}
    \F_{-n-1} \subset \F_{-n} 
\end{equation*} An adapted process $(X_{-n}, \F_{-n})$ is a backward martingale if \begin{enumerate}
    \item Adapted: $X_{-n} \in \F_{-n}$
    \item $\E\abs{X_{-n}} <\infty$
    \item Martingale property: 
    \begin{equation*}
        X_{-n-1} = \E(X_{-n}|\F_{-n-1})
    \end{equation*}
\end{enumerate}

\begin{thm}[Backward martingale convergence theorem]
\label{BMCT} Let $(X_{-n}, \F_{-n})$ be a backward martingale and let $\F_{-\infty} = \bigi{n=0}^\infty \F_{-n}$ then there exists $X_{-\infty}$ \begin{enumerate}
    \item $X_{-\infty} = \biglim{n\rightarrow \infty} X_{-n}$ a.s.
    \item $X_{-n} \xrightarrow{\ls{1}} X_{-\infty}$
    \item $X_{-\infty} = \E(X_0 | \F_{-\infty})$
\end{enumerate}
\begin{equation*}
     \qquad 
\end{equation*}

\begin{rem}
No assumption of u.i. because $\forall n, X_{-n} = \E(X_0|\F_{-n})$ and $\E(|X_0|) <\infty$ by definition then we get u.i.
\end{rem}
\end{thm}
\begin{example}
$\xi_k, k \geq 1$ be i.i.d random variables with $\E \xi_k = 0, S_n = \bigs{k=1}^n \xi_k$ Define \begin{align*}
    \F_{-n} &= \sigma(S_n, S_{n+1}, ...) \\
    &= \sigma(S_n, \xi_{n+1},\xi_{n+2}, ...) \\
    X_{-n} &= \frac{S_n}{n}
\end{align*}Claim: $(X_{-n}, \F_{-n})$ is a backward martingale
\end{example}

\newpage
\subsection{Quadratic variation}
\begin{dfn}[martingale difference sequence]
An adapted sequence $(\xi_n ,\F_n)$ is a martingale difference sequence if \begin{enumerate}
    \item $ \E\abs{\xi_k} < \infty$
    \item $\E(\xi_{k+1}|\F_k) = 0$
\end{enumerate}
\end{dfn}
\begin{example}
Let $M_n =\bigs{i=1}^n \xi_i, M_0 = 0$ and $(M_n, \F_n)$ is a martingale then $\xi_n = M_n - M_{n-1}$ is martingale difference sequence
\begin{enumerate}
    \item $\forall k, \E\abs{\xi_k} \leq \E\abs{M_n} +\E\abs{M_{n-1}} <\infty$
    \item $\E(\xi_{k+1}|\F_k) = \E(M_{k+1} - M_{k}|\F_k) = 0$ By martingale property.
\end{enumerate}
\end{example}
\vspace{2cm}

\begin{thm}[Doob decomposition theorem]
\label{Doobdecomp}
Let $(X_n, \F_n)$ be submartingale. Then there exists a martingale $(M_n, \F_n)$ and a predictable increasing sequence $(A_n, \F_{n-1})$ starting with $A_0 = 0$ s.t. The decomposition is unique in a.s. sense.
\begin{equation*}
    X_n = M_n + A_n
\end{equation*}
\end{thm}
\pf \\
\textbf{Existence:} Define $M_0 = X_0$ and the process
\begin{align*}
    &M_n = M_0 + \bigs{k=1}^n(X_k - \E[X_k|\F_{k-1}]) \\
    &A_n = \bigs{k=1}^n(\E[X_k|\F_{k-1}]- X_{k-1}) \in \F_{n-1} \quad \text{Being adapted} \\
    &\forall k, \E[X_k|\F_{k-1}]- X_{k-1} \geq 0 \implies A_n\uparrow \\
    &M_{n} - M_{n-1} = X_n - \E[X_n|\F_{n-1}] \\
    &\E(M_{n} - M_{n-1}|\F_{n-1}) = \E(X_n - \E[X_n|\F_{n-1}]|\F_{n-1}) = 0 \text{ a.s.} \\
\end{align*}
\textbf{Uniqueness:}
Let $X_n = M'+A' $ be an additional decomposition and let $Y_n:= M-M' = A' - A$ which is a martingale and predictable process, hence \begin{equation*}
    \E(Y_n |\F_{n-1}) = Y_n \text{ a.s. } \quad \E(Y_n |\F_{n-1}) = Y_{n-1} \text{ a.s. } \quad \forall n\geq 1
\end{equation*}Notice $Y_0 = A'_0 - A_0 = 0$ this implies iteratively that $Y_n = 0$ a.s for all n, hence the decomposition is almost surely unique.

\newpage
Let $(M_n, \F_n)$ be a martingale $\E M_n^2 <\infty ,\forall n$ then $(M_n^2, \F_n)$ is a submartingale by Jensen's inequality. Then by \ref{Doobdecomp} theorem, 
\begin{equation*}
    M_n^2 = m_n + A_n
\end{equation*}s.t. $(m_n, \F_n)$ be a martingale, $(A_n, \F_{n-1})$ be an increasing process.

\begin{dfn}[Predictable quadratic variation] For a process $M$ \begin{align*}
    A_n = \pqvar{M}  &= \bigs{k=1}^n(\E[M_k^2|\F_{k-1}]- M_{k-1}^2) \\
    &= \bigs{k=1}^n \E\big[(M_k - M_{k-1})^2| \F_{k-1}\big] \\
    \implies& M_n^2 = m_n + \pqvar{M}
\end{align*}
\end{dfn}

\begin{dfn}[Optional quadratic variation] For a process $M$
\begin{align*}
    \oqvar{M}  &= \bigs{k=1}^n (M_k -M_{k-1})^2
\end{align*}
\end{dfn}

\begin{rem}If the process stars at $0$ s.t.
\begin{align*}
    &M_n^2 = m_n + \pqvar{M} \\
    &M_0 = 0 \implies m_0 = 0 \\
    \implies& \E(M_n^2) = \E(m_n + \pqvar{M}) = \E(\pqvar{M})
\end{align*}
\end{rem}

\vfill
\begin{example}
$\xi_k$ i.i.d with $\E\xi_k = 0, \E\xi_k^2 <\infty$ Then we define $M_n = \bigs{k=1}^n \xi_k, M_0 = 0$
\begin{align*}
    \pqvar{M} &= \bigs{k=1}^n \E\big[(M_k - M_{k-1})^2| \F_{k-1}\big] = \bigs{k=1}^n \E\big[\,\xi_k^2| \F_{k-1}\big] =\bigs{k=1}^n \E \,\xi_n^2 \\
    \oqvar{M}  &= \bigs{k=1}^n (M_k -M_{k-1})^2 = \bigs{k=1}^n \E \,\xi_n^2
\end{align*} Which coincides in this case. also use the next theorem \ref{SLLNM} \\
If $\pqvar{M} \rightarrow \infty$ then $\frac{M_n}{\pqvar{M}}  = \frac{\xi_1 + ,..., \xi_n}{Var(\xi_1 + ,..., \xi_n)}\xrightarrow{a.s.} 0$
\end{example}

\newpage
\begin{thm}[Strong law of large numbers for martingale]
\label{SLLNM}
Let $(M_n, \F_n)$ be a martingale, $\E M_n^2<\infty$ then \begin{equation*}
    \prob\big(\frac{M_n}{\pqvar{M}} \text{ Converges}\big) = 1
\end{equation*}
\begin{rem}
Now consider two situations of quadratic variation: \\
$\pqvar{M} \rightarrow \infty \quad a.s. \implies \frac{M_n}{\pqvar{M}} \rightarrow 0 \qquad a.s.$\\
$\pqvar{M} < \infty \quad \implies M_n\rightarrow \qquad a.s.$\\ This is proved in theorem \ref{Convergeqvar}
\end{rem}
\end{thm}

\begin{dfn} Converges sequence notation
\begin{equation*}
    \{\omega; X_n(\omega) \text{ converges}\} := \{X_n \rightarrow\}
\end{equation*}
\end{dfn}
\begin{example}
In MCT \ref{SMCT} Let $(X_n, \F_n)$ be a submartingale assume
\begin{equation*}
    \sup\limits_n \E\abs{X_n} < \infty
\end{equation*}
Then $\biglim{n} X_n = X_\infty$ a.s. Here we denote as 
\begin{equation*}
    \{X_n \rightarrow\} = \Omega\setminus N = \Omega \quad a.s
\end{equation*}Where N is null set (zero measure)
\end{example}

\begin{dfn}
Let $(X_n, \F_n)$ be adapted sequence $Y\in C^+$ if
\begin{equation*}
    \E[(\triangle X_{\tau_a})^+ \I_{(\tau_a < \infty)}] < \infty
\end{equation*}Where $\triangle X_n = X_n - X_{n-1}$, $\tau_a = \inf\{n\geq 1, X_n >a\} ,a\in \R$
\end{dfn}

\newpage
\begin{thm}
If $(X_n, \F_n)$ is a submartingale and $(X_n) \in C^+$ then 
\begin{equation*}
    \{\supunder{n} X_n < \infty\} = \{X_n \rightarrow\} \quad a.s.
\end{equation*}
\end{thm}
\begin{cor}
    Let $(X_n, \F_n)$ is a martingale and $\E[\supunder{n} \abs{\triangle X_n}] < \infty$ then 
    \begin{equation*}
        \{X_n \rightarrow\} \cup \{\linf{n} X_n = -\infty, \lsup{n} X_n = \infty\} = \Omega \quad a.s.
    \end{equation*}
\end{cor}
\pf

\newpage

\begin{example}
$X_n = \bigs{k=1}^n \xi_k,\,\xi_k \, i.i.d$ with $\E(\xi_k) = 0, \prob(|\xi_k| > c) >0$ makes the rv non trivial. Here $X_n$ is a martingale.
\begin{equation*}
    \{\linf{n} X_n = -\infty, \lsup{n} X_n = \infty\} = \Omega \quad a.s.
\end{equation*}Since sum of i.i.d random variables does not converge. (not trivial)
\end{example}
\begin{example}
$X_n = \bigs{k=1}^n \xi_k$ independent but not identical, with $\E(\xi_k) = 0, \abs{\xi_k} \leq c$ \\
Here $X_n$ is a martingale. 
\begin{align*}
    \pqvar{X} = \bigs{k=1}^n \E[\xi_k^2] \quad {\langle{X} \rangle}_\infty = \bigs{k=1}^\infty \E[\xi_k^2]
\end{align*}
Then by Strong law of large numbers for martingale
\begin{equation*}
    \{{\langle{X} \rangle}_\infty <\infty\} = \{X_n \rightarrow\}
\end{equation*} That is, $\{X_n \rightarrow\}$ iff $\bigs{k=1}^\infty \E[\xi_k^2] <\infty$
\end{example}

\begin{lem}
Let $(X_n, \F_n)$ is a submartingale then
\begin{equation*}
    (X_{n\wedge\tau}, \F_n)
\end{equation*} is a submartingale where $\tau$ is any stopping time.
\end{lem}

\newpage 
\begin{thm}
Let $(X_n, \F_n)$ is a submartingale then by Doob's decomposition
\begin{equation*}
    X_n = m_n + A_n
\end{equation*}where $m_n$ is a martingale and $A_n$ is an increasing predictable sequence starts from 0 then:
\begin{enumerate}
    \item If $X_n \geq 0$ a.s. then \begin{equation*}
        \{A_\infty < \infty\} \subset \{X_n \rightarrow\} \subset \{\supunder{n} X_n < \infty\}
    \end{equation*}
    \item If $(X_n)\in C^+$ then \begin{equation*}
         \{X_n \rightarrow\} = \{\supunder{n} X_n < \infty\}\subset \{A_\infty < \infty\} 
    \end{equation*}
\end{enumerate}
\end{thm}
\begin{cor}
    Obviously, if $X_n \geq 0$ and $(X_n)\in C^+$ we have \begin{equation*}
         \{X_n \rightarrow\} = \{\supunder{n} X_n < \infty\} = \{A_\infty < \infty\} 
    \end{equation*}
\end{cor}

\newpage
\begin{example}
Let $X_n = \bigs{k=1}^n \xi_k$ (no independency needed), with $\E(\xi_k) <\infty$, Here $X_n$ is a submartingale. As before we can decompose by Doob's theorem 
\begin{align*}
    A_n &= \bigs{i=1}^n [\E(X_{i}|\F_{i-1}) -X_{i-1}] = \bigs{i=1}^n \E[\xi_i|\F_{i-1}] \\
    A_\infty &= \bigs{i=1}^\infty \E[\xi_i|\F_{i-1}]
    \intertext{Then}
    &\{\bigs{i=1}^\infty \E[\xi_i|\F_{i-1}] <\infty\} \subset \{X_n \rightarrow\}
    \intertext{If $\E\supunder{n}\xi_n <\infty$ then $(X_n)\in C^+$} 
    &\{\bigs{i=1}^\infty \E[\xi_i|\F_{i-1}] <\infty\} = \{X_n \rightarrow\}
\end{align*}
\end{example}

\begin{cor}[Extension of Borel-Cantelli's lemma]
Let $B_n \in \F_n, \xi_n = \I_{B_n}$, then
\begin{equation*}
    \{\bigs{i=1}^n \E[B_i|\F_{i-1}] <\infty\} = \{\bigs{i=1}^\infty \I_{B_n} <\infty \}
\end{equation*}RHS is the set when $B$ occurs infinitly often.
\end{cor}

\newpage
\begin{thm}
\label{Convergeqvar}
Let $(M_n, \F_n)$ be submartingale with $\E[M_n^2] < \infty$ then \begin{align*}
    \{{\langle{M} \rangle}_\infty < \infty\} \subset \{M_n \rightarrow\} a.s. 
    \intertext{Moreover, $\E[\supunder{n}\abs{\triangle M_n}^2] <\infty$ then}
    \{{\langle{M} \rangle}_\infty < \infty\} = \{M_n \rightarrow\} a.s. 
\end{align*}
\end{thm}
\pf 
\newpage


\begin{thm}
Let $(M_n, \F_n)$ be martingale with $\E[M_n^2] < \infty$, $(A_n,\F_{n-1})$ be predictable non-decreasing sequences with $A_1 \geq 1, A_\infty = \infty$ if
\begin{equation*}
    \bigs{i}\frac{\E[(\triangle M_i)^2 |\F_{i-1}]}{A_i^2} < \infty
\end{equation*} then 
\begin{equation*}
    \frac{M_n}{A_n} \xrightarrow{a.s} 0
\end{equation*}
\end{thm}
\begin{rem}
If $\pqvar{M} \xrightarrow{n\rightarrow \infty} \infty$ then we take $A_n = \pqvar{M}$ then we have Strong law of large number for martingale \ref{SLLNM}
\end{rem}
\begin{lem}[Kronecker Lemma]
\label{Kronecker} Let $b_n \uparrow \infty, b_n >0, \bigs{n=1}^\infty x_n $ converges then 
\begin{equation*}
    \frac{1}{b_n}\bigs{i=1}^n b_i x_i \xrightarrow{n\rightarrow \infty} 0
\end{equation*}
\end{lem}

\newpage
Optimal quadratic variation: $\oqvar{X} = \bigs{k=1}^n (X_k -X_{k-1})^2$
\begin{thm}[Burkholder-Davis-Gundy inequalities]
\label{BDG}
Let $p\in [1,\infty)$ then there exist numbers $A_p, B_p > 0$ s.t. for any martingale $X_n$ we have 
\begin{equation*}
    A_p\E [X]_N^{p/2} \leq \E[\supunder{n\leq N}\abs{X_n}^p] \leq B_p \E [X]_N^{p/2}
\end{equation*}
\end{thm}

\begin{thm}
Let $(X_n, \F_n)$ be a martingale then \begin{equation*}
    \norm{X_n^*}_p \leq \frac{p}{p-1} \norm{X_n}_p
\end{equation*}$X_n^*:= \max\limits_{k\leq n} \abs{X_k}, \norm{X}_p = [\E\abs{X}^p]^{1/p}$
\end{thm}


\newpage
\section{Absolute continuity}

Let $\prob, \Q$ be probability measure on $(\Omega, \F)$ 
\begin{dfn}
    $\prob$ is absolutely continuous w.r.t $\Q$ if:
    \begin{equation*}
        \forall A\in\F \quad \Q(A)=  0 \implies \prob(A)= 0
    \end{equation*}Denote as $\prob\ll\Q$
\end{dfn}\vspace{0.5cm}
\begin{dfn}
    $\prob$ and $\Q$ are equivalent if:
    \begin{equation*}
        \forall A\in\F \quad \Q(A)=  0 \text{ iff } \prob(A)= 0
    \end{equation*}Denote as $\prob\sim\Q$
\end{dfn}\vspace{0.5cm}
\begin{dfn}[Radon-Nikodym derivative]
    If $\prob$ is absolutely continuous w.r.t $\Q$, $\prob\ll\Q$ we define \begin{equation*}
        \frac{\diff \Q}{\diff \prob} = X,\quad s.t. \E_\Q (Y) = \into Y\diff \Q = \into Y X \diff \prob = \E_\prob (XY)
    \end{equation*}
\end{dfn}
\begin{dfn}
    $\prob$ and $\Q$ are singular if:
    \begin{equation*}
        \exists A\in\F \quad \Q(A)=  0, \prob(A)= 1
    \end{equation*}Denote as $\prob\perp\Q$
\end{dfn}
\newpage
\textbf{Settings:} Let $(\Omega, \F)$ be measurable space for single experiment,$\prob_0, \Q_0$ be two probability measures, $X_1$ be r.v.then define
\begin{align*}
    \Omega &= \Omega_0 \bigotimes \Omega_0 ... \\
    X_1, &X_2, ... \text{r.vs being independent with distribution $\prob_k, \Q_k$}\\
    \F_n &= \sigma(x_1, ... X_n) \\
    \F_\infty &= \sigma(x_1, ... X_n, ...) \\
    \prob &= \prob_1 \bigotimes \prob_2 ... \\
    \Q &= \Q \bigotimes \Q ... \\
\end{align*} 

\begin{thm}[Kakutani] \label{Kakutani}
Assume $\frac{\diff \Q_n}{\diff \prob_n} = g_n(X_n), Q_n \ll \prob_n$ Let $f_n = g_1(X_1) \cdot ... \cdot g_n(X_n)$ then 
\begin{enumerate}
    \item $(f_n, \F_n)$ is a $\prob-$ martingale
    \item Let $\tau$ be an $(\F_n)$ stopping time s.t. $\prob(\tau < \infty) =1, \Q(\tau < \infty) =1$ then 
    \begin{equation*}
        f_\tau = \frac{\diff \Q}{\diff \prob}\big|_{\F_\tau}
    \end{equation*}
    \item Either $Q \ll \prob$ or $Q \perp \prob$
    \begin{enumerate}
        \item If $\bigp{n=1}^\infty \int_{\Omega_0} \sqrt{g_n} \diff \prob_n >0$ then
        \begin{enumerate}
            \item $f_n \rightarrow f_\infty \quad \prob-a.s.$
            \item $f_n \xrightarrow{\ls{1}} f_\infty$
            \item $f_\infty = \frac{\diff \Q}{\diff \prob}\big|_{\F_\infty}$
        \end{enumerate}
        \item If $\bigp{n=1}^\infty \int_{\Omega_0} \sqrt{g_n} \diff \prob_n =0\quad$ then
        \begin{enumerate}
            \item $f_n \rightarrow 0 \quad \prob-a.s.$
            \item $f_n \rightarrow \infty \quad \Q-a.s.$
        \end{enumerate}
    \end{enumerate}
\end{enumerate}
\end{thm}

\newpage 
\pf \\
\begin{enumerate}
    \item $f_n = g_1(X_1) \cdot ... \cdot g_n(X_n)$ being independent because $X_n$ are independent.
    \begin{enumerate}
        \item $\E_\prob\abs{f_n} = \E_\prob f_n = \bigp{k=1}^n \E_\prob g_k(X_k) = \bigp{k=1}^n \int \frac{\diff \Q_k}{\diff \prob_k} \diff \prob_k = \bigp{k=1}^n \int \diff \Q_k = 1$ 
        \item $f_n \in \F_n$ being adapted.
        \item $\E_\prob(f_{n+1}|\F_n) = f_n \E_\prob(g_{n+1}|\F_n) = f_n$
    \end{enumerate}
    \item Take $B_1, B_2, ..., B_n \in \F_0$ then
    \begin{align*}
        \Q(B_1\times B_2 \times ... \times B_n \times \Omega_0 \times \Omega_0 \times... ) &= \bigp{k=1}^n\Q_k(B_k) = \bigp{k=1}^n \int_{B_k} g_k(X_k) \diff\prob_k \\
        &= \int_{B_1\times B_2 \times ... \times B_n \times \Omega_0...} g_1(X_1)\cdot...\cdot g_n(X_n) \diff\prob \\
        &= \int_{B_1\times B_2 \times ... \times B_n \times \Omega_0...} f_n \diff\prob
    \end{align*}By $\pi-\lambda$ system lemma, we may extend to all $B\in \F_n$ s.s. \begin{equation*}
        \Q(B) = \int_B f_n \diff \prob
    \end{equation*}
    Take $B\in\F_\tau, B\cap \{\tau = n\}\in \F_n$ 
    \begin{align*}
        \Q(B) &= \Q(B\cap \{\tau < \infty\}) = \bigs{n=1}^\infty \Q(B\cap \{\tau = n\}) \\
        &= \bigs{n=1}^\infty \int_{B\cap \{\tau = n\}} f_n \diff\prob \\
        &= \int_{B\cap \{\tau < \infty\}} f_\tau \diff\prob = \int_{B} f_\tau \diff\prob \\
        &\implies f_\tau = \frac{\diff \Q}{\diff \prob}\big|_{\F_\tau}
    \end{align*}
    \item $0 \leq \int_{\Omega_0} \sqrt{g_n} \diff\prob_n \stackrel{Jensen}{\leq} \sqrt{\int_{\Omega_0} g_n \diff\prob_n} =1 \implies 0\leq \bigp{n=1}^\infty \int_{\Omega_0} \sqrt{g_n} \diff\prob_n <\infty$
    \begin{enumerate}
        \item If $\bigp{n=1}^\infty \int_{\Omega_0} \sqrt{g_n} \diff \prob_n >0$
    \end{enumerate}
\end{enumerate}
